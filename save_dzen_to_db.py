"""
–°–±–æ—Ä –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–µ–π –∏–∑ –î–∑–µ–Ω –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
"""
import sys
sys.stdout.reconfigure(encoding='utf-8')

from dotenv import load_dotenv
load_dotenv(override=True, encoding='utf-8')

from collect_dzen_duckduckgo import DzenDuckDuckGoCollector
from models import db, Review
from analyzers.sentiment_analyzer import SentimentAnalyzer
from analyzers.moderator import Moderator
from app_enhanced import app
import logging

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def main():
    print("="*70)
    print("–°–ë–û–† –ò –°–û–•–†–ê–ù–ï–ù–ò–ï –ù–û–í–û–°–¢–ï–ô –ò–ó –Ø–ù–î–ï–ö–°.–î–ó–ï–ù")
    print("="*70)
    
    # –°–±–æ—Ä –Ω–æ–≤–æ—Å—Ç–µ–π
    collector = DzenDuckDuckGoCollector()
    articles = collector.collect()
    
    if not articles:
        print("\n‚ùå –ù–æ–≤–æ—Å—Ç–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        return
    
    print("\n" + "="*70)
    print("–°–û–•–†–ê–ù–ï–ù–ò–ï –í –ë–ê–ó–£ –î–ê–ù–ù–´–•")
    print("="*70)
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–æ–≤
    sentiment_analyzer = SentimentAnalyzer()
    moderator = Moderator()
    
    saved = 0
    skipped = 0
    
    with app.app_context():
        for article_data in articles:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
            existing = Review.query.filter_by(source_id=article_data['source_id']).first()
            if existing:
                logger.info(f"‚äò –ü—Ä–æ–ø—É—â–µ–Ω–æ (–¥—É–±–ª–∏–∫–∞—Ç): {article_data['text'][:50]}...")
                skipped += 1
                continue
            
            # –ê–Ω–∞–ª–∏–∑ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏
            sentiment = sentiment_analyzer.analyze(article_data['text'])
            keywords = sentiment_analyzer.extract_keywords(article_data['text'])
            
            # –ú–æ–¥–µ—Ä–∞—Ü–∏—è
            moderation_status, moderation_reason, requires_manual = moderator.moderate(
                article_data['text'],
                sentiment['sentiment_score']
            )
            
            # –°–æ–∑–¥–∞–Ω–∏–µ –∑–∞–ø–∏—Å–∏
            review = Review(
                source=article_data['source'],
                source_id=article_data['source_id'],
                author=article_data.get('author'),
                author_id=article_data.get('author_id'),
                text=article_data['text'],
                url=article_data.get('url'),
                published_date=article_data.get('published_date'),
                sentiment_score=sentiment['sentiment_score'],
                sentiment_label=sentiment['sentiment_label'],
                keywords=','.join(keywords) if keywords else None,
                moderation_status=moderation_status,
                moderation_reason=moderation_reason,
                requires_manual_review=requires_manual,
                processed=not requires_manual
            )
            
            db.session.add(review)
            logger.info(f"‚úì –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {article_data['text'][:50]}...")
            saved += 1
        
        db.session.commit()
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        total = Review.query.count()
        zen_count = Review.query.filter_by(source='zen').count()
        
        print("\n" + "="*70)
        print("–†–ï–ó–£–õ–¨–¢–ê–¢–´")
        print("="*70)
        print(f"‚úì –ù–æ–≤—ã—Ö —Å—Ç–∞—Ç–µ–π —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {saved}")
        print(f"‚äò –ü—Ä–æ–ø—É—â–µ–Ω–æ (–¥—É–±–ª–∏–∫–∞—Ç—ã): {skipped}")
        print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö:")
        print(f"   –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {total}")
        print(f"   –°—Ç–∞—Ç–µ–π –∏–∑ –î–∑–µ–Ω: {zen_count}")
        print("\n‚úì –ì–æ—Ç–æ–≤–æ! –û—Ç–∫—Ä–æ–π—Ç–µ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å:")
        print("   python app_enhanced.py")
        print("   http://localhost:5000")
        print("="*70)

if __name__ == '__main__':
    main()
